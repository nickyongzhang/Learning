{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "Example script showing how to use a stateful LSTM model\n",
    "and how its stateless counterpart performs.\n",
    "\n",
    "More documentation about the Keras LSTM model can be found at\n",
    "https://keras.io/layers/recurrent/#lstm\n",
    "\n",
    "The models are trained on an input/output pair, where\n",
    "the input is a generated uniformly distributed\n",
    "random sequence of length = \"input_len\",\n",
    "and the output is a moving average of the input with window length = \"tsteps\".\n",
    "Both \"input_len\" and \"tsteps\" are defined in the \"editable parameters\" section.\n",
    "\n",
    "A larger \"tsteps\" value means that the LSTM will need more memory\n",
    "to figure out the input-output relationship.\n",
    "This memory length is controlled by the \"lahead\" variable (more details below).\n",
    "\n",
    "The rest of the parameters are:\n",
    "- input_len: the length of the generated input sequence\n",
    "- lahead: the input sequence length that the LSTM\n",
    "  is trained on for each output point\n",
    "- batch_size, epochs: same parameters as in the model.fit(...) function\n",
    "\n",
    "When lahead > 1, the model input is preprocessed to a \"rolling window view\"\n",
    "of the data, with the window length = \"lahead\".\n",
    "This is similar to sklearn's \"view_as_windows\"\n",
    "with \"window_shape\" being a single number\n",
    "Ref: http://scikit-image.org/docs/0.10.x/api/skimage.util.html#view-as-windows\n",
    "\n",
    "When lahead < tsteps, only the stateful LSTM converges because its\n",
    "statefulness allows it to see beyond the capability that lahead\n",
    "gave it to fit the n-point average. The stateless LSTM does not have\n",
    "this capability, and hence is limited by its \"lahead\" parameter,\n",
    "which is not sufficient to see the n-point average.\n",
    "\n",
    "When lahead >= tsteps, both the stateful and stateless LSTM converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1001"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_drop = max(tsteps - 1, lahead - 1)\n",
    "data_input = gen_uniform_amp(amp=0.1, xn=input_len + to_drop)\n",
    "\n",
    "# set the target to be a N-point average of the input\n",
    "expected_output = data_input.rolling(window=tsteps, center=False).mean()\n",
    "\n",
    "if lahead > 1:\n",
    "    data_input = np.repeat(data_input.values, repeats=lahead, axis=1)\n",
    "    data_input = pd.DataFrame(data_input)\n",
    "    for i, c in enumerate(data_input.columns):\n",
    "        data_input[c] = data_input[c].shift(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/yong.zhang/.pyenv/versions/3.6.4/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************\n",
      "STATELESS LSTM WILL NOT CONVERGE\n",
      "*********************************\n",
      "Generating Data...\n",
      "Input shape: (1000, 1)\n",
      "Output shape: (1000, 1)\n",
      "Input head: \n",
      "          0\n",
      "1 -0.084532\n",
      "2  0.021696\n",
      "3  0.079500\n",
      "4  0.008981\n",
      "5  0.040544\n",
      "Output head: \n",
      "          0\n",
      "1 -0.035379\n",
      "2 -0.031418\n",
      "3  0.050598\n",
      "4  0.044240\n",
      "5  0.024763\n",
      "Input tail: \n",
      "             0\n",
      "996   0.010251\n",
      "997  -0.027833\n",
      "998   0.003984\n",
      "999   0.028471\n",
      "1000 -0.057877\n",
      "Output tail: \n",
      "             0\n",
      "996   0.025187\n",
      "997  -0.008791\n",
      "998  -0.011925\n",
      "999   0.016227\n",
      "1000 -0.014703\n",
      "Plotting input and expected output\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x110a15588>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x110a15d68>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x110a15d30>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Input')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Stateful Model...\n",
      "x_train.shape:  (800, 1, 1)\n",
      "y_train.shape:  (800, 1)\n",
      "x_test.shape:  (200, 1, 1)\n",
      "y_test.shape:  (200, 1)\n",
      "Training\n",
      "Epoch 1 / 10\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 3s 4ms/step - loss: 5.9438e-04 - val_loss: 4.9195e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x110b76550>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 / 10\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 2.9328e-04 - val_loss: 2.6493e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x110b762e8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 / 10\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 2.4383e-04 - val_loss: 2.1706e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11231b240>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 / 10\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 2.4226e-04 - val_loss: 2.0737e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11231b128>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 / 10\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 2.4903e-04 - val_loss: 2.0842e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11231b208>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 / 10\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 2.5576e-04 - val_loss: 2.0635e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11231b048>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 / 10\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 2.5527e-04 - val_loss: 2.0433e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x110b762e8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 / 10\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 2.5741e-04 - val_loss: 2.0687e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11231b240>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 / 10\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 2.5246e-04 - val_loss: 2.1076e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x110b76550>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 / 10\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 2.5617e-04 - val_loss: 2.1720e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11231b080>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting\n",
      "Creating Stateless Model...\n",
      "Training\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 8.5858e-04 - val_loss: 0.0010\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 8.5562e-04 - val_loss: 0.0010\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 8.5407e-04 - val_loss: 9.9548e-04\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 8.5305e-04 - val_loss: 9.8785e-04\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 8.5231e-04 - val_loss: 9.8180e-04\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 8.5167e-04 - val_loss: 9.7660e-04\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 8.5112e-04 - val_loss: 9.7192e-04\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 8.5062e-04 - val_loss: 9.6776e-04\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 8.5015e-04 - val_loss: 9.6395e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11231b2e8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting\n",
      "Plotting Results\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x112bbc898>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x112279c88>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Expected')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x112b5e240>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x112b74160>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Stateful: Expected - Predicted')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x112b2b630>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x112b2b550>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Stateless: Expected - Predicted')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# EDITABLE PARAMETERS\n",
    "# Read the documentation in the script head for more details\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "# length of input\n",
    "input_len = 1000\n",
    "\n",
    "# The window length of the moving average used to generate\n",
    "# the output from the input in the input/output pair used\n",
    "# to train the LSTM\n",
    "# e.g. if tsteps=2 and input=[1, 2, 3, 4, 5],\n",
    "#      then output=[1.5, 2.5, 3.5, 4.5]\n",
    "tsteps = 2\n",
    "\n",
    "# The input sequence length that the LSTM is trained on for each output point\n",
    "lahead = 1\n",
    "\n",
    "# training parameters passed to \"model.fit(...)\"\n",
    "batch_size = 1\n",
    "epochs = 10\n",
    "\n",
    "# ------------\n",
    "# MAIN PROGRAM\n",
    "# ------------\n",
    "\n",
    "print(\"*\" * 33)\n",
    "if lahead >= tsteps:\n",
    "    print(\"STATELESS LSTM WILL ALSO CONVERGE\")\n",
    "else:\n",
    "    print(\"STATELESS LSTM WILL NOT CONVERGE\")\n",
    "print(\"*\" * 33)\n",
    "\n",
    "np.random.seed(1986)\n",
    "\n",
    "print('Generating Data...')\n",
    "\n",
    "\n",
    "def gen_uniform_amp(amp=1, xn=10000):\n",
    "    \"\"\"Generates uniform random data between\n",
    "    -amp and +amp\n",
    "    and of length xn\n",
    "\n",
    "    Arguments:\n",
    "        amp: maximum/minimum range of uniform data\n",
    "        xn: length of series\n",
    "    \"\"\"\n",
    "    data_input = np.random.uniform(-1 * amp, +1 * amp, xn)\n",
    "    data_input = pd.DataFrame(data_input)\n",
    "    return data_input\n",
    "\n",
    "# Since the output is a moving average of the input,\n",
    "# the first few points of output will be NaN\n",
    "# and will be dropped from the generated data\n",
    "# before training the LSTM.\n",
    "# Also, when lahead > 1,\n",
    "# the preprocessing step later of \"rolling window view\"\n",
    "# will also cause some points to be lost.\n",
    "# For aesthetic reasons,\n",
    "# in order to maintain generated data length = input_len after pre-processing,\n",
    "# add a few points to account for the values that will be lost.\n",
    "to_drop = max(tsteps - 1, lahead - 1)\n",
    "data_input = gen_uniform_amp(amp=0.1, xn=input_len + to_drop)\n",
    "\n",
    "# set the target to be a N-point average of the input\n",
    "expected_output = data_input.rolling(window=tsteps, center=False).mean()\n",
    "\n",
    "# when lahead > 1, need to convert the input to \"rolling window view\"\n",
    "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html\n",
    "if lahead > 1:\n",
    "    data_input = np.repeat(data_input.values, repeats=lahead, axis=1)\n",
    "    data_input = pd.DataFrame(data_input)\n",
    "    for i, c in enumerate(data_input.columns):\n",
    "        data_input[c] = data_input[c].shift(i)\n",
    "\n",
    "# drop the nan\n",
    "expected_output = expected_output[to_drop:]\n",
    "data_input = data_input[to_drop:]\n",
    "\n",
    "print('Input shape:', data_input.shape)\n",
    "print('Output shape:', expected_output.shape)\n",
    "print('Input head: ')\n",
    "print(data_input.head())\n",
    "print('Output head: ')\n",
    "print(expected_output.head())\n",
    "print('Input tail: ')\n",
    "print(data_input.tail())\n",
    "print('Output tail: ')\n",
    "print(expected_output.tail())\n",
    "\n",
    "print('Plotting input and expected output')\n",
    "plt.plot(data_input[0][:10], '.')\n",
    "plt.plot(expected_output[0][:10], '-')\n",
    "plt.legend(['Input', 'Expected output'])\n",
    "plt.title('Input')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def create_model(stateful):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(20,\n",
    "              input_shape=(lahead, 1),\n",
    "              batch_size=batch_size,\n",
    "              stateful=stateful))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "print('Creating Stateful Model...')\n",
    "model_stateful = create_model(stateful=True)\n",
    "\n",
    "\n",
    "# split train/test data\n",
    "def split_data(x, y, ratio=0.8):\n",
    "    to_train = int(input_len * ratio)\n",
    "    # tweak to match with batch_size\n",
    "    to_train -= to_train % batch_size\n",
    "\n",
    "    x_train = x[:to_train]\n",
    "    y_train = y[:to_train]\n",
    "    x_test = x[to_train:]\n",
    "    y_test = y[to_train:]\n",
    "\n",
    "    # tweak to match with batch_size\n",
    "    to_drop = x.shape[0] % batch_size\n",
    "    if to_drop > 0:\n",
    "        x_test = x_test[:-1 * to_drop]\n",
    "        y_test = y_test[:-1 * to_drop]\n",
    "\n",
    "    # some reshaping\n",
    "    reshape_3 = lambda x: x.values.reshape((x.shape[0], x.shape[1], 1))\n",
    "    x_train = reshape_3(x_train)\n",
    "    x_test = reshape_3(x_test)\n",
    "\n",
    "    reshape_2 = lambda x: x.values.reshape((x.shape[0], 1))\n",
    "    y_train = reshape_2(y_train)\n",
    "    y_test = reshape_2(y_test)\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = split_data(data_input, expected_output)\n",
    "print('x_train.shape: ', x_train.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('x_test.shape: ', x_test.shape)\n",
    "print('y_test.shape: ', y_test.shape)\n",
    "\n",
    "print('Training')\n",
    "for i in range(epochs):\n",
    "    print('Epoch', i + 1, '/', epochs)\n",
    "    # Note that the last state for sample i in a batch will\n",
    "    # be used as initial state for sample i in the next batch.\n",
    "    # Thus we are simultaneously training on batch_size series with\n",
    "    # lower resolution than the original series contained in data_input.\n",
    "    # Each of these series are offset by one step and can be\n",
    "    # extracted with data_input[i::batch_size].\n",
    "    model_stateful.fit(x_train,\n",
    "                       y_train,\n",
    "                       batch_size=batch_size,\n",
    "                       epochs=1,\n",
    "                       verbose=1,\n",
    "                       validation_data=(x_test, y_test),\n",
    "                       shuffle=False)\n",
    "    model_stateful.reset_states()\n",
    "\n",
    "print('Predicting')\n",
    "predicted_stateful = model_stateful.predict(x_test, batch_size=batch_size)\n",
    "\n",
    "print('Creating Stateless Model...')\n",
    "model_stateless = create_model(stateful=False)\n",
    "\n",
    "print('Training')\n",
    "model_stateless.fit(x_train,\n",
    "                    y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    shuffle=False)\n",
    "\n",
    "print('Predicting')\n",
    "predicted_stateless = model_stateless.predict(x_test, batch_size=batch_size)\n",
    "\n",
    "# ----------------------------\n",
    "\n",
    "print('Plotting Results')\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(y_test)\n",
    "plt.title('Expected')\n",
    "plt.subplot(3, 1, 2)\n",
    "# drop the first \"tsteps-1\" because it is not possible to predict them\n",
    "# since the \"previous\" timesteps to use do not exist\n",
    "plt.plot((y_test - predicted_stateful).flatten()[tsteps - 1:])\n",
    "plt.title('Stateful: Expected - Predicted')\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot((y_test - predicted_stateless).flatten())\n",
    "plt.title('Stateless: Expected - Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
