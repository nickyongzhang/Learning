{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural doodle with Keras\n",
    "# Script Usage\n",
    "## Arguments\n",
    "```\n",
    "--nlabels:              # of regions (colors) in mask images\n",
    "--style-image:          image to learn style from\n",
    "--style-mask:           semantic labels for style image\n",
    "--target-mask:          semantic labels for target image (your doodle)\n",
    "--content-image:        optional image to learn content from\n",
    "--target-image-prefix:  path prefix for generated target images\n",
    "```\n",
    "## Example 1: doodle using a style image, style mask\n",
    "and target mask.\n",
    "```\n",
    "python neural_doodle.py --nlabels 4 --style-image Monet/style.png \\\n",
    "--style-mask Monet/style_mask.png --target-mask Monet/target_mask.png \\\n",
    "--target-image-prefix generated/monet\n",
    "```\n",
    "## Example 2: doodle using a style image, style mask, target mask and an optional content image.\n",
    "```\n",
    "python neural_doodle.py --nlabels 4 --style-image Renoir/style.png \\\n",
    "--style-mask Renoir/style_mask.png --target-mask Renoir/target_mask.png \\\n",
    "--content-image Renoir/creek.jpg \\\n",
    "--target-image-prefix generated/renoir\n",
    "```\n",
    "# References\n",
    "- [Dmitry Ulyanov's blog on fast-neural-doodle]\n",
    "    (http://dmitryulyanov.github.io/feed-forward-neural-doodle/)\n",
    "- [Torch code for fast-neural-doodle]\n",
    "    (https://github.com/DmitryUlyanov/fast-neural-doodle)\n",
    "- [Torch code for online-neural-doodle]\n",
    "    (https://github.com/DmitryUlyanov/online-neural-doodle)\n",
    "- [Paper Texture Networks: Feed-forward Synthesis of Textures and Stylized Images]\n",
    "    (http://arxiv.org/abs/1603.03417)\n",
    "- [Discussion on parameter tuning]\n",
    "    (https://github.com/keras-team/keras/issues/3705)\n",
    "# Resources\n",
    "Example images can be downloaded from\n",
    "https://github.com/DmitryUlyanov/fast-neural-doodle/tree/master/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, AveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
    "from keras.applications import vgg19\n",
    "\n",
    "# Command line arguments\n",
    "parser = argparse.ArgumentParser(description='Keras neural doodle example')\n",
    "parser.add_argument('--nlabels', type=int,\n",
    "                    help='number of semantic labels'\n",
    "                    ' (regions in differnet colors)'\n",
    "                    ' in style_mask/target_mask')\n",
    "parser.add_argument('--style-image', type=str,\n",
    "                    help='path to image to learn style from')\n",
    "parser.add_argument('--style-mask', type=str,\n",
    "                    help='path to semantic mask of style image')\n",
    "parser.add_argument('--target-mask', type=str,\n",
    "                    help='path to semantic mask of target image')\n",
    "parser.add_argument('--content-image', type=str, default=None,\n",
    "                    help='path to optional content image')\n",
    "parser.add_argument('--target-image-prefix', type=str,\n",
    "                    help='path prefix for generated results')\n",
    "args = parser.parse_args()\n",
    "\n",
    "style_img_path = args.style_image\n",
    "style_mask_path = args.style_mask\n",
    "target_mask_path = args.target_mask\n",
    "content_img_path = args.content_image\n",
    "target_img_prefix = args.target_image_prefix\n",
    "use_content_img = content_img_path is not None\n",
    "\n",
    "num_labels = args.nlabels\n",
    "num_colors = 3  # RGB\n",
    "# determine image sizes based on target_mask\n",
    "ref_img = img_to_array(load_img(target_mask_path))\n",
    "img_nrows, img_ncols = ref_img.shape[:2]\n",
    "\n",
    "total_variation_weight = 50.\n",
    "style_weight = 1.\n",
    "content_weight = 0.1 if use_content_img else 0\n",
    "\n",
    "content_feature_layers = ['block5_conv2']\n",
    "# To get better generation qualities, use more conv layers for style features\n",
    "style_feature_layers = ['block1_conv1', 'block2_conv1', 'block3_conv1',\n",
    "                        'block4_conv1', 'block5_conv1']\n",
    "\n",
    "\n",
    "# helper functions for reading/processing images\n",
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(img_nrows, img_ncols))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = vgg19.preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def deprocess_image(x):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.reshape((3, img_nrows, img_ncols))\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    else:\n",
    "        x = x.reshape((img_nrows, img_ncols, 3))\n",
    "    # Remove zero-center by mean pixel\n",
    "    x[:, :, 0] += 103.939\n",
    "    x[:, :, 1] += 116.779\n",
    "    x[:, :, 2] += 123.68\n",
    "    # 'BGR'->'RGB'\n",
    "    x = x[:, :, ::-1]\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "\n",
    "def kmeans(xs, k):\n",
    "    assert xs.ndim == 2\n",
    "    try:\n",
    "        from sklearn.cluster import k_means\n",
    "        _, labels, _ = k_means(xs.astype('float64'), k)\n",
    "    except ImportError:\n",
    "        from scipy.cluster.vq import kmeans2\n",
    "        _, labels = kmeans2(xs, k, missing='raise')\n",
    "    return labels\n",
    "\n",
    "\n",
    "def load_mask_labels():\n",
    "    '''Load both target and style masks.\n",
    "    A mask image (nr x nc) with m labels/colors will be loaded\n",
    "    as a 4D boolean tensor:\n",
    "        (1, m, nr, nc) for 'channels_first' or (1, nr, nc, m) for 'channels_last'\n",
    "    '''\n",
    "    target_mask_img = load_img(target_mask_path,\n",
    "                               target_size=(img_nrows, img_ncols))\n",
    "    target_mask_img = img_to_array(target_mask_img)\n",
    "    style_mask_img = load_img(style_mask_path,\n",
    "                              target_size=(img_nrows, img_ncols))\n",
    "    style_mask_img = img_to_array(style_mask_img)\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        mask_vecs = np.vstack([style_mask_img.reshape((3, -1)).T,\n",
    "                               target_mask_img.reshape((3, -1)).T])\n",
    "    else:\n",
    "        mask_vecs = np.vstack([style_mask_img.reshape((-1, 3)),\n",
    "                               target_mask_img.reshape((-1, 3))])\n",
    "\n",
    "    labels = kmeans(mask_vecs, num_labels)\n",
    "    style_mask_label = labels[:img_nrows *\n",
    "                              img_ncols].reshape((img_nrows, img_ncols))\n",
    "    target_mask_label = labels[img_nrows *\n",
    "                               img_ncols:].reshape((img_nrows, img_ncols))\n",
    "\n",
    "    stack_axis = 0 if K.image_data_format() == 'channels_first' else -1\n",
    "    style_mask = np.stack([style_mask_label == r for r in range(num_labels)],\n",
    "                          axis=stack_axis)\n",
    "    target_mask = np.stack([target_mask_label == r for r in range(num_labels)],\n",
    "                           axis=stack_axis)\n",
    "\n",
    "    return (np.expand_dims(style_mask, axis=0),\n",
    "            np.expand_dims(target_mask, axis=0))\n",
    "\n",
    "\n",
    "# Create tensor variables for images\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    shape = (1, num_colors, img_nrows, img_ncols)\n",
    "else:\n",
    "    shape = (1, img_nrows, img_ncols, num_colors)\n",
    "\n",
    "style_image = K.variable(preprocess_image(style_img_path))\n",
    "target_image = K.placeholder(shape=shape)\n",
    "if use_content_img:\n",
    "    content_image = K.variable(preprocess_image(content_img_path))\n",
    "else:\n",
    "    content_image = K.zeros(shape=shape)\n",
    "\n",
    "images = K.concatenate([style_image, target_image, content_image], axis=0)\n",
    "\n",
    "# Create tensor variables for masks\n",
    "raw_style_mask, raw_target_mask = load_mask_labels()\n",
    "style_mask = K.variable(raw_style_mask.astype('float32'))\n",
    "target_mask = K.variable(raw_target_mask.astype('float32'))\n",
    "masks = K.concatenate([style_mask, target_mask], axis=0)\n",
    "\n",
    "# index constants for images and tasks variables\n",
    "STYLE, TARGET, CONTENT = 0, 1, 2\n",
    "\n",
    "# Build image model, mask model and use layer outputs as features\n",
    "# image model as VGG19\n",
    "image_model = vgg19.VGG19(include_top=False, input_tensor=images)\n",
    "\n",
    "# mask model as a series of pooling\n",
    "mask_input = Input(tensor=masks, shape=(None, None, None), name='mask_input')\n",
    "x hygju m[ v√√√˙v vblvb=8bv=g     mkm jjjuh n.i]\n",
    "    elif 'pool' in layer.name:\n",
    "        x = AveragePooling2D((2, 2), name=name)(x)\n",
    "mask_model = Model(mask_input, x)\n",
    "\n",
    "# Collect features from image_model and task_model\n",
    "image_features = {}\n",
    "mask_features = {}\n",
    "for img_layer, mask_layer in zip(image_model.layers, mask_model.layers):\n",
    "    if 'conv' in img_layer.name:\n",
    "        assert 'mask_' + img_layer.name == mask_layer.name\n",
    "        layer_name = img_layer.name\n",
    "        img_feat, mask_feat = img_layer.output, mask_layer.output\n",
    "        image_features[layer_name] = img_feat\n",
    "        mask_features[layer_name] = mask_feat\n",
    "\n",
    "\n",
    "# Define loss functions\n",
    "def gram_matrix(x):\n",
    "    assert K.ndim(x) == 3\n",
    "    features = K.batch_flatten(x)\n",
    "    gram = K.dot(features, K.transpose(features))\n",
    "    return gram\n",
    "\n",
    "\n",
    "def region_style_loss(style_image, target_image, style_mask, target_mask):\n",
    "    '''Calculate style loss between style_image and target_image,\n",
    "    for one common region specified by their (boolean) masks\n",
    "    '''\n",
    "    assert 3 == K.ndim(style_image) == K.ndim(target_image)\n",
    "    assert 2 == K.ndim(style_mask) == K.ndim(target_mask)\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        masked_style = style_image * style_mask\n",
    "        masked_target = target_image * target_mask\n",
    "        num_channels = K.shape(style_image)[0]\n",
    "    else:\n",
    "        masked_style = K.permute_dimensions(\n",
    "            style_image, (2, 0, 1)) * style_mask\n",
    "        masked_target = K.permute_dimensions(\n",
    "            target_image, (2, 0, 1)) * target_mask\n",
    "        num_channels = K.shape(style_image)[-1]\n",
    "    num_channels = K.cast(num_channels, dtype='float32')\n",
    "    s = gram_matrix(masked_style) / K.mean(style_mask) / num_channels\n",
    "    c = gram_matrix(masked_target) / K.mean(target_mask) / num_channels\n",
    "    return K.mean(K.square(s - c))\n",
    "\n",
    "\n",
    "def style_loss(style_image, target_image, style_masks, target_masks):\n",
    "    '''Calculate style loss between style_image and target_image,\n",
    "    in all regions.\n",
    "    '''\n",
    "    assert 3 == K.ndim(style_image) == K.ndim(target_image)\n",
    "    assert 3 == K.ndim(style_masks) == K.ndim(target_masks)\n",
    "    loss = K.variable(0)\n",
    "    for i in range(num_labels):\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            style_mask = style_masks[i, :, :]\n",
    "            target_mask = target_masks[i, :, :]\n",
    "        else:\n",
    "            style_mask = style_masks[:, :, i]\n",
    "            target_mask = target_masks[:, :, i]\n",
    "        loss += region_style_loss(style_image,\n",
    "                                  target_image, style_mask, target_mask)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def content_loss(content_image, target_image):\n",
    "    return K.sum(K.square(target_image - content_image))\n",
    "\n",
    "\n",
    "def total_variation_loss(x):\n",
    "    assert 4 == K.ndim(x)\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        a = K.square(x[:, :, :img_nrows - 1, :img_ncols - 1] -\n",
    "                     x[:, :, 1:, :img_ncols - 1])\n",
    "        b = K.square(x[:, :, :img_nrows - 1, :img_ncols - 1] -\n",
    "                     x[:, :, :img_nrows - 1, 1:])\n",
    "    else:\n",
    "        a = K.square(x[:, :img_nrows - 1, :img_ncols - 1, :] -\n",
    "                     x[:, 1:, :img_ncols - 1, :])\n",
    "        b = K.square(x[:, :img_nrows - 1, :img_ncols - 1, :] -\n",
    "                     x[:, :img_nrows - 1, 1:, :])\n",
    "    return K.sum(K.pow(a + b, 1.25))\n",
    "\n",
    "\n",
    "# Overall loss is the weighted sum of content_loss, style_loss and tv_loss\n",
    "# Each individual loss uses features from image/mask models.\n",
    "loss = K.variable(0)\n",
    "for layer in content_feature_layers:\n",
    "    content_feat = image_features[layer][CONTENT, :, :, :]\n",
    "    target_feat = image_features[layer][TARGET, :, :, :]\n",
    "    loss += content_weight * content_loss(content_feat, target_feat)\n",
    "\n",
    "for layer in style_feature_layers:\n",
    "    style_feat = image_features[layer][STYLE, :, :, :]\n",
    "    target_feat = image_features[layer][TARGET, :, :, :]\n",
    "    style_masks = mask_features[layer][STYLE, :, :, :]\n",
    "    target_masks = mask_features[layer][TARGET, :, :, :]\n",
    "    sl = style_loss(style_feat, target_feat, style_masks, target_masks)\n",
    "    loss += (style_weight / len(style_feature_layers)) * sl\n",
    "\n",
    "loss += total_variation_weight * total_variation_loss(target_image)\n",
    "loss_grads = K.gradients(loss, target_image)\n",
    "\n",
    "# Evaluator class for computing efficiency\n",
    "outputs = [loss]\n",
    "if isinstance(loss_grads, (list, tuple)):\n",
    "    outputs += loss_grads\n",
    "else:\n",
    "    outputs.append(loss_grads)\n",
    "\n",
    "f_outputs = K.function([target_image], outputs)\n",
    "\n",
    "\n",
    "def eval_loss_and_grads(x):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.reshape((1, 3, img_nrows, img_ncols))\n",
    "    else:\n",
    "        x = x.reshape((1, img_nrows, img_ncols, 3))\n",
    "    outs = f_outputs([x])\n",
    "    loss_value = outs[0]\n",
    "    if len(outs[1:]) == 1:\n",
    "        grad_values = outs[1].flatten().astype('float64')\n",
    "    else:\n",
    "        grad_values = np.array(outs[1:]).flatten().astype('float64')\n",
    "    return loss_value, grad_values\n",
    "\n",
    "\n",
    "class Evaluator(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.loss_value = None\n",
    "        self.grads_values = None\n",
    "\n",
    "    def loss(self, x):\n",
    "        assert self.loss_value is None\n",
    "        loss_value, grad_values = eval_loss_and_grads(x)\n",
    "        self.loss_value = loss_value\n",
    "        self.grad_values = grad_values\n",
    "        return self.loss_value\n",
    "\n",
    "    def grads(self, x):\n",
    "        assert self.loss_value is not None\n",
    "        grad_values = np.copy(self.grad_values)\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "        return grad_values\n",
    "\n",
    "evaluator = Evaluator()\n",
    "\n",
    "# Generate images by iterative optimization\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x = np.random.uniform(0, 255, (1, 3, img_nrows, img_ncols)) - 128.\n",
    "else:\n",
    "    x = np.random.uniform(0, 255, (1, img_nrows, img_ncols, 3)) - 128.\n",
    "\n",
    "for i in range(50):\n",
    "    print('Start of iteration', i)\n",
    "    start_time = time.time()\n",
    "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n",
    "                                     fprime=evaluator.grads, maxfun=20)\n",
    "    print('Current loss value:', min_val)\n",
    "    # save current generated image\n",
    "    img = deprocess_image(x.copy())\n",
    "    fname = target_img_prefix + '_at_iteration_%d.png' % i\n",
    "    save_img(fname, img)\n",
    "    end_time = time.time()\n",
    "    print('Image saved as', fname)\n",
    "    print('Iteration %d completed in %ds' % (i, end_time - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
